{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACE RECOGNITION FOR DATA SCIENCE TEAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import  required libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dropout,BatchNormalization,Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8984 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "#data generation for training data\n",
    "train_gen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.1,horizontal_flip=False,validation_split=0.15)\n",
    "#train dataset\n",
    "train_data=train_gen.flow_from_directory(r\"C:\\Users\\hp\\Desktop\\VS Code\\Face_Recognition_Python_Team\\Data\\Train\",\n",
    "                                          target_size=(224,224),batch_size=32,class_mode=\"categorical\",subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arun': 0,\n",
       " 'chaitanya': 1,\n",
       " 'laxmi': 2,\n",
       " 'navin': 3,\n",
       " 'papu': 4,\n",
       " 'priti': 5,\n",
       " 'rahul': 6,\n",
       " 'sangram': 7,\n",
       " 'sanket': 8}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classes name\n",
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1580 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation dataset\n",
    "validation_data=train_gen.flow_from_directory(r\"C:\\Users\\hp\\Desktop\\VS Code\\Face_Recognition_Python_Team\\Data\\Train\",\n",
    "                                          target_size=(224,224),batch_size=32,class_mode=\"categorical\",subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arun': 0,\n",
       " 'chaitanya': 1,\n",
       " 'laxmi': 2,\n",
       " 'navin': 3,\n",
       " 'papu': 4,\n",
       " 'priti': 5,\n",
       " 'rahul': 6,\n",
       " 'sangram': 7,\n",
       " 'sanket': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classes name\n",
    "validation_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD CNN ARCHITECTURE USING TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function of CNN for image classification\n",
    "def cnn_model(activation_function,number_of_classes,optimizer_name):\n",
    "\n",
    "    #MOBILENETV2\n",
    "    mob_net=MobileNetV2(weights=\"imagenet\",input_shape=(224,224,3),include_top=False)\n",
    "    mob_net.trainable=False\n",
    "    \n",
    "    #create a sequential model\n",
    "    model=Sequential()\n",
    "    #add mobilenet model to sequential model\n",
    "    model.add(mob_net)\n",
    "    #convert the model into 1d array\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #1st fully connnected layer with dropout and batchnormalization\n",
    "    model.add(Dense(units=64,activation=activation_function))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #2st fully connnected layer with dropout and batchnormalization\n",
    "    model.add(Dense(units=32,activation=activation_function))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    #3st fully connnected layer with dropout\n",
    "    model.add(Dense(units=16,activation=activation_function))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #final output layer with softmax activation function\n",
    "    model.add(Dense(units=number_of_classes,activation=\"softmax\"))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(optimizer=optimizer_name,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    \n",
    "    #return our cnn model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 62720)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4014144   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,275,273\n",
      "Trainable params: 4,017,097\n",
      "Non-trainable params: 2,258,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#call our cnn model with relu activation function and adam optimizer\n",
    "model=cnn_model(\"relu\",9,\"adam\")\n",
    "#summmary of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "281/281 [==============================] - 617s 2s/step - loss: 1.0931 - accuracy: 0.6450 - val_loss: 0.3218 - val_accuracy: 0.9335\n",
      "Epoch 2/10\n",
      "281/281 [==============================] - 666s 2s/step - loss: 0.3507 - accuracy: 0.9014 - val_loss: 0.1817 - val_accuracy: 0.9418\n",
      "Epoch 3/10\n",
      "281/281 [==============================] - 791s 3s/step - loss: 0.2444 - accuracy: 0.9270 - val_loss: 0.1633 - val_accuracy: 0.9544\n",
      "Epoch 4/10\n",
      "281/281 [==============================] - 770s 3s/step - loss: 0.1971 - accuracy: 0.9410 - val_loss: 0.1463 - val_accuracy: 0.9582\n",
      "Epoch 5/10\n",
      "281/281 [==============================] - 855s 3s/step - loss: 0.1513 - accuracy: 0.9556 - val_loss: 0.1471 - val_accuracy: 0.9639\n",
      "Epoch 6/10\n",
      "281/281 [==============================] - 898s 3s/step - loss: 0.1390 - accuracy: 0.9566 - val_loss: 0.1909 - val_accuracy: 0.9456\n",
      "Epoch 7/10\n",
      "281/281 [==============================] - 664s 2s/step - loss: 0.1457 - accuracy: 0.9559 - val_loss: 0.1192 - val_accuracy: 0.9747\n",
      "Epoch 8/10\n",
      "281/281 [==============================] - 591s 2s/step - loss: 0.1252 - accuracy: 0.9646 - val_loss: 0.1493 - val_accuracy: 0.9652\n",
      "Epoch 9/10\n",
      "281/281 [==============================] - 654s 2s/step - loss: 0.1255 - accuracy: 0.9628 - val_loss: 0.1540 - val_accuracy: 0.9589\n",
      "Epoch 10/10\n",
      "281/281 [==============================] - 692s 2s/step - loss: 0.1114 - accuracy: 0.9657 - val_loss: 0.1459 - val_accuracy: 0.9665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b13626e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply early stopping for avoid overfitting\n",
    "es=EarlyStopping(monitor=\"accuracy\",patience=3)\n",
    "#train our model\n",
    "model.fit(train_data,validation_data=validation_data,callbacks=[es],epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save our model in h5 format\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "63963b3f4c440940f0b94a3100916033a226cb4f45979123153792d60aa56d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
